{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aaea611",
   "metadata": {},
   "source": [
    "Importar librer√≠as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e72be65",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer\n",
    "import yaml\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "from google.colab import files\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12540d2a",
   "metadata": {},
   "source": [
    "Librer√≠as RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ddaf98",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q langchain chromadb sentence-transformers\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45f6cbc",
   "metadata": {},
   "source": [
    "Ruta al modelo LLaMA y CSV en el drive vinculado anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab31d595",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model_dir = \"/content/drive/MyDrive/llama/llama-2-7b-chat-hf\"\n",
    "csv_path = \"/content/drive/MyDrive/contexto_RAG.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e58f2e0",
   "metadata": {},
   "source": [
    "Implementaci√≥n RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e548aecc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "loader = CSVLoader(file_path=csv_path)\n",
    "docs = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "documents = text_splitter.split_documents(docs)\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectordb = Chroma.from_documents(documents=documents, embedding=embedding, persist_directory=\"./db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83f0991",
   "metadata": {},
   "source": [
    "Generar respuesta con IA generativa (LLAMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411e1663",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def generate_response(prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=256).to(\"cuda\")\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_length=256,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        top_k=50,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c05d91",
   "metadata": {},
   "source": [
    "Generar resumen LLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3015f5a0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def generar_resumen_llama_breve(config, table_config):\n",
    "    entrada = \", \".join([f['name'] for f in config['input_features']])\n",
    "    salida = \", \".join([f['name'] for f in config['output_features']])\n",
    "    separador = table_config['separator']\n",
    "    faltantes = table_config['missing_data']\n",
    "\n",
    "    prompt = (\n",
    "        f\"¬øCu√°l es el prop√≥sito de este modelo?\\n\"\n",
    "        f\"- Entradas: {entrada}\\n\"\n",
    "        f\"- Salida: {salida}\\n\"\n",
    "        f\"- Separador: {separador}\\n\"\n",
    "        f\"- Tratamiento de valores faltantes: {faltantes}\\n\\n\"\n",
    "        f\"Respuesta (solo un p√°rrafo en espa√±ol, sin repetir la pregunta):\"\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=150,\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        top_k=50,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response.replace(prompt, \"\").strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802f4297",
   "metadata": {},
   "source": [
    "Funci√≥n de ayuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1795d069",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def ayuda_mode(question):\n",
    "    retrived_docs = vectordb.similarity_search(question, k=1)\n",
    "    contexto = retrived_docs[0].page_content if retrived_docs else \"\"\n",
    "    prompt = f\"\"\"Usa el siguiente contexto para explicar al usuario de forma clara y sencilla. Si el contexto no es √∫til, responde de forma general:\n",
    "Contexto: {contexto}\n",
    "\n",
    "Pregunta: {question}\n",
    "Respuesta:\"\"\"\n",
    "    raw = generate_response(prompt)\n",
    "    print(\"üîç Ayuda LLaMA:\\n\" + wrap_text(raw.replace(prompt, \"\").strip()))\n",
    "    print(wrap_text(contexto))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464f75b4",
   "metadata": {},
   "source": [
    "Bucle de preguntas al usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a57988",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def ask_question(prompt, options=None):\n",
    "    while True:\n",
    "        print(f\"\\nChatbot LLaMA: {prompt}\")\n",
    "        if options:\n",
    "            for i, option in enumerate(options, 1):\n",
    "                print(f\"  {i}. {option}\")\n",
    "            user_input = input(\"Selecciona una opci√≥n (n√∫mero): \")\n",
    "            if user_input.strip().lower().startswith(\"ayuda:\"):\n",
    "                ayuda_mode(user_input.replace(\"ayuda:\", \"\").strip())\n",
    "                continue\n",
    "            if user_input.isdigit():\n",
    "                idx = int(user_input)\n",
    "                if 1 <= idx <= len(options):\n",
    "                    return options[idx - 1].split(':')[0].strip()\n",
    "            print(\"\\n‚ùå Entrada inv√°lida. Por favor, introduce el n√∫mero correspondiente a una de las opciones mostradas.\")\n",
    "        else:\n",
    "            user_input = input(\"T√∫: \")\n",
    "            if user_input.strip().lower().startswith(\"ayuda:\"):\n",
    "                ayuda_mode(user_input.replace(\"ayuda:\", \"\").strip())\n",
    "                continue\n",
    "            return user_input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d683ccb5",
   "metadata": {},
   "source": [
    "Creaci√≥n del YML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072c81ae",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def create_yaml(config, filename=\"config.yml\"):\n",
    "    with open(filename, \"w\") as file:\n",
    "        yaml.dump(config, file)\n",
    "    print(f\"Archivo {filename} creado correctamente.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef00aefb",
   "metadata": {},
   "source": [
    "Inicio Main: Bienvenida al usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3360bde6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Chatbot LLaMA: Bienvenido a la interfaz de AutoML ü§ñ\")\n",
    "print(\"Puedes responder normalmente a las preguntas que ir√© haciendo.\")\n",
    "print(\"Si tienes dudas escribe: ayuda: tu pregunta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c31610",
   "metadata": {},
   "source": [
    "Subida y carga del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7418fa85",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "uploaded = files.upload()\n",
    "for filename in uploaded.keys():\n",
    "    file_path = filename\n",
    "\n",
    "data, meta = arff.loadarff(file_path)\n",
    "df = pd.DataFrame(data)\n",
    "print(f\"Archivo cargado: {file_path}\\nColumnas: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80991d90",
   "metadata": {},
   "source": [
    "Configuraci√≥n y opciones de valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f372a7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "config = {\"input_features\": [], \"output_features\": []}\n",
    "table_config = {}\n",
    "\n",
    "separator_options = [\n",
    "    \"comma: Columnas separadas por comas.\",\n",
    "    \"semicolon: Columnas separadas por punto y coma.\",\n",
    "    \"backslash: Columnas separadas por barra invertida.\"\n",
    "]\n",
    "missing_data_options = [\n",
    "    \"fill_with_const: Valor espec√≠fico.\",\n",
    "    \"fill_with_mode: Valor m√°s frecuente.\",\n",
    "    \"fill_with_mean: Media.\",\n",
    "    \"fill_with_false: Valor falso.\",\n",
    "    \"bfill: Valor siguiente.\",\n",
    "    \"ffill: Valor anterior.\",\n",
    "    \"drop_row: Eliminar fila.\"\n",
    "]\n",
    "feature_role_options = [\n",
    "    \"input: Entrada.\",\n",
    "    \"output: Salida.\",\n",
    "    \"ninguna: Ignorar.\"\n",
    "]\n",
    "input_type_options = [\n",
    "    \"binary: Binario.\",\n",
    "    \"number: Num√©rico.\",\n",
    "    \"category: Categ√≥rico.\",\n",
    "    \"text: Texto.\",\n",
    "    \"vector: Vector.\",\n",
    "    \"image: Imagen.\",\n",
    "    \"audio: Audio.\",\n",
    "    \"timeseries: Serie temporal.\",\n",
    "    \"date: Fecha.\"\n",
    "]\n",
    "target_type_options = [\n",
    "    \"binary: Binario.\",\n",
    "    \"number: Num√©rico.\",\n",
    "    \"category: Categ√≥rico.\",\n",
    "    \"bag: Bolsa.\",\n",
    "    \"set: Conjunto.\",\n",
    "    \"sequence: Secuencia.\",\n",
    "    \"text: Texto.\",\n",
    "    \"vector: Vector.\",\n",
    "    \"audio: Audio.\",\n",
    "    \"date: Fecha.\",\n",
    "    \"h3: H3.\",\n",
    "    \"image: Imagen.\",\n",
    "    \"timeseries: Serie temporal.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2fc6a7",
   "metadata": {},
   "source": [
    "Preguntas al usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8bdce5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\nChatbot LLaMA: Vamos a configurar tus datos.\")\n",
    "table_config[\"separator\"] = ask_question(\"Separador de columnas:\", separator_options)\n",
    "table_config[\"missing_data\"] = ask_question(\"¬øC√≥mo tratar los datos faltantes?\", missing_data_options)\n",
    "\n",
    "for column in df.columns:\n",
    "    role = ask_question(f\"Uso para la columna '{column}':\", feature_role_options)\n",
    "    if role == \"input\":\n",
    "        tipo = ask_question(f\"Tipo de dato de '{column}':\", input_type_options)\n",
    "        config[\"input_features\"].append({\"name\": str(column), \"type\": tipo})\n",
    "    elif role == \"output\":\n",
    "        tipo = ask_question(f\"Tipo de objetivo de '{column}':\", target_type_options)\n",
    "        config[\"output_features\"].append({\"name\": str(column), \"type\": tipo})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bd6068",
   "metadata": {},
   "source": [
    "Guardado y descarga del YML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e5e238",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "config[\"preprocessing\"] = {\n",
    "    \"separator\": table_config[\"separator\"],\n",
    "    \"missing_value_strategy\": table_config[\"missing_data\"]\n",
    "}\n",
    "\n",
    "create_yaml(config)\n",
    "files.download(\"config.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1045d19c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Resumen de configuraci√≥n y fin de programa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ac1cc1",
   "metadata": {},
   "source": [
    "print(\"\\nüìú Resumen de configuraci√≥n:\")\n",
    "print(wrap_text(generar_resumen_llama_breve(config, table_config)))\n",
    "print(\"\\nüìÖ LLaMA: ¬°Proceso terminado y archivo YAML listo para usar con Ludwig!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
